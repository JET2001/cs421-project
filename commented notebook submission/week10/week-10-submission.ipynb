{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 10 Model Submission\n",
    "\n",
    "**Feature Engineering**\n",
    "\n",
    "To create user-specific and interaction-level features:\n",
    "1. User-based Metrics: Aggregated user statistics such as mean, standard deviation, and kurtosis of ratings. Interaction counts for likes, dislikes, neutrals, and watched actions were calculated.\n",
    "2. Ratio Features: Ratios of each interaction type relative to the total interactions were derived.\n",
    "3. Weighted Scores: Weighted scores were computed using likes and dislikes to reflect user sentiment.\n",
    "4. Item Popularity: A popularity score for each item was calculated by combining the average rating and the log-scaled count of interactions.\n",
    "5. Deviation Metrics: For each user, the average deviation from item popularity was calculated.\n",
    "6. Outlier Removal: Outliers were filtered using the interquartile range for robust feature quality.\n",
    "\n",
    "**Data Engineering**\n",
    "\n",
    "The first and second batch dataset was used for training and testing.\n",
    "\n",
    "**Feature Preprocessing**\n",
    "\n",
    "Feature preprocessing involves a two-stage scaling approach:\n",
    "1. Scaling: Standard scaling was applied to normalize the feature distributions.\n",
    "2. Feature Selection: Features with high correlation or limited utility were excluded to reduce redundancy.\n",
    "\n",
    "**Model Training**\n",
    "1. Base Model: Logistic Regression wrapped in a One-vs-Rest classifier for multi-class classification.\n",
    "Hyperparameter Optimization:\n",
    "2. RandomizedSearchCV was used with 10-fold cross-validation to optimize hyperparameters such as C, solver type, and tolerance.\n",
    "3. Penalty types (L1 and L2) were explored to handle feature sparsity effectively.\n",
    "4. Evaluation Metric: ROC-AUC for multi-class classification (roc_auc_ovr) was used as the scoring criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.01)\n",
    "        Q3 = df[col].quantile(0.99)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the outlier range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Remove rows with outliers\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def engineer_features(df_X, feature_columns=None, df_y=None):\n",
    "    # Basic user features\n",
    "    df_user_features = df_X.groupby(\"user\").agg(\n",
    "        mean_rating=(\"rating\", \"mean\"),\n",
    "        median_rating=(\"rating\", \"median\"),\n",
    "        std_rating=(\"rating\", \"std\"),\n",
    "        count_dislike=(\"rating\", lambda x: (x == -10).sum()),\n",
    "        count_neutral=(\"rating\", lambda x: (x == 0).sum()),\n",
    "        count_like=(\"rating\", lambda x: (x == 10).sum()),\n",
    "        count_watched=(\"rating\", lambda x: (x == 1).sum()),\n",
    "        total_interactions=(\"rating\", \"count\"),\n",
    "    )\n",
    "\n",
    "    # Ratio features\n",
    "    df_user_features[\"like_ratio\"] = (\n",
    "        df_user_features[\"count_like\"] / df_user_features[\"total_interactions\"]\n",
    "    )\n",
    "    df_user_features[\"dislike_ratio\"] = (\n",
    "        df_user_features[\"count_dislike\"] / df_user_features[\"total_interactions\"]\n",
    "    )\n",
    "    df_user_features[\"neutral_ratio\"] = (\n",
    "        df_user_features[\"count_neutral\"] / df_user_features[\"total_interactions\"]\n",
    "    )\n",
    "    df_user_features[\"watched_ratio\"] = (\n",
    "        df_user_features[\"count_watched\"] / df_user_features[\"total_interactions\"]\n",
    "    )\n",
    "\n",
    "    # Weighted scores\n",
    "    df_user_features[\"weighted_score\"] = (\n",
    "        df_user_features[\"count_like\"] * 1.5 - df_user_features[\"count_dislike\"] * 1.5\n",
    "    )\n",
    "\n",
    "    # Distribution features\n",
    "    df_user_features[\"rating_kurtosis\"] = df_X.groupby(\"user\")[\"rating\"].apply(\n",
    "        lambda x: kurtosis(x)\n",
    "    )\n",
    "\n",
    "    # Item popularity metrics\n",
    "    item_popularity = df_X.groupby(\"item\")[\"rating\"].agg([\"mean\", \"count\"])\n",
    "    item_popularity[\"popularity_score\"] = item_popularity[\"mean\"] * np.log1p(\n",
    "        item_popularity[\"count\"]\n",
    "    )\n",
    "\n",
    "    # Merge item popularity with user interactions\n",
    "    df_X_with_popularity = pd.merge(\n",
    "        df_X, item_popularity[\"popularity_score\"], left_on=\"item\", right_index=True\n",
    "    )\n",
    "\n",
    "    # New features\n",
    "    df_user_features[\"avg_deviation_from_popularity\"] = df_X_with_popularity.groupby(\n",
    "        \"user\"\n",
    "    ).apply(lambda x: np.abs(x[\"rating\"] - x[\"popularity_score\"]).mean())\n",
    "\n",
    "    # Drop columns with high correlation\n",
    "    df_user_features.drop(columns=[\"total_interactions\", \"median_rating\"], inplace=True)\n",
    "\n",
    "    # If labels are provided, merge with df_y\n",
    "    if df_y is not None:\n",
    "        df_user_features = remove_outliers(df_user_features, df_user_features.columns)\n",
    "        df_merged = pd.merge(df_user_features.reset_index(), df_y, on=\"user\")\n",
    "        feature_columns = df_user_features.columns.tolist()\n",
    "\n",
    "        # Return the merged dataframe with selected features, label, and selected features\n",
    "        return df_merged[[\"user\"] + feature_columns + [\"label\"]], feature_columns\n",
    "\n",
    "    # If no labels (unseen data), just select the selected features\n",
    "    else:\n",
    "        if feature_columns is None:\n",
    "            raise ValueError(\"feature_columns must be provided for unseen data\")\n",
    "\n",
    "        df_merged = df_user_features.reset_index()\n",
    "        return df_merged[[\"user\"] + feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/sdxgwhg55dzc67hr8x63hdv80000gn/T/ipykernel_53683/3664850182.py:68: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ).apply(lambda x: np.abs(x[\"rating\"] - x[\"popularity_score\"]).mean())\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Logistic Regression): {'estimator__warm_start': False, 'estimator__tol': 0.0001, 'estimator__solver': 'newton-cg', 'estimator__penalty': 'l2', 'estimator__max_iter': 2000, 'estimator__C': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "30 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/multiclass.py\", line 370, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/multiclass.py\", line 93, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/milton/Documents/GitHub/cs421-project/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.97294489 0.9625673  0.97342359 0.96258317 0.97344708 0.96258317\n",
      " 0.97300156        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_first = np.load(\"first_second_batch_multi_labels.npz\")\n",
    "X_first = data_first[\"X\"]\n",
    "y_first = data_first[\"yy\"]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_X_first = pd.DataFrame(X_first, columns=[\"user\", \"item\", \"rating\"])\n",
    "df_y_first = pd.DataFrame(y_first, columns=[\"user\", \"label\"])\n",
    "\n",
    "# Engineer features for the first dataset\n",
    "df_merged_first, top_features = engineer_features(df_X_first, df_y=df_y_first)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Features and Labels\n",
    "X_features_first = df_merged_first.drop(columns=[\"user\", \"label\"])\n",
    "y_labels_first = df_merged_first[\"label\"]\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_features_first)\n",
    "\n",
    "# Define base logistic regression model\n",
    "base_logreg = LogisticRegression(random_state=RANDOM_SEED)\n",
    "\n",
    "# Wrap it with OneVsRestClassifier\n",
    "ovr_logreg = OneVsRestClassifier(base_logreg)\n",
    "\n",
    "# Define parameter grid for logistic regression\n",
    "param_grid_logreg = {\n",
    "    \"estimator__C\": [0.1, 1, 10, 35, 100],  # Wider range of C values\n",
    "    \"estimator__penalty\": [\"l2\", \"l1\"],  # Include L1 penalty\n",
    "    \"estimator__solver\": [\"newton-cg\", \"lbfgs\", \"saga\"],  # Include saga solver\n",
    "    \"estimator__max_iter\": [1000, 2000, 3000],  # Increased max_iter\n",
    "    \"estimator__tol\": [1e-4, 1e-5, 1e-6],  # Adjusted tolerance levels\n",
    "    \"estimator__warm_start\": [True, False],\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV for logistic regression\n",
    "random_search_logreg = RandomizedSearchCV(\n",
    "    estimator=ovr_logreg,\n",
    "    param_distributions=param_grid_logreg,\n",
    "    # Increase to 100 will marginally improve the results\n",
    "    n_iter=10,\n",
    "    scoring=\"roc_auc_ovr\",\n",
    "    cv=10,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data (first dataset)\n",
    "random_search_logreg.fit(X_train_scaled, y_labels_first)\n",
    "\n",
    "# Print the best parameters found by RandomizedSearchCV\n",
    "print(f\"Best Parameters (Logistic Regression): {random_search_logreg.best_params_}\")\n",
    "\n",
    "# Use the best logistic regression model from RandomizedSearchCV\n",
    "best_logreg_model = random_search_logreg.best_estimator_\n",
    "model = best_logreg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p2/sdxgwhg55dzc67hr8x63hdv80000gn/T/ipykernel_53683/3664850182.py:68: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ).apply(lambda x: np.abs(x[\"rating\"] - x[\"popularity_score\"]).mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.061739</td>\n",
       "      <td>0.929657</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.053339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2202</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.978741</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2203</td>\n",
       "      <td>0.889322</td>\n",
       "      <td>0.110299</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2204</td>\n",
       "      <td>0.448965</td>\n",
       "      <td>0.535102</td>\n",
       "      <td>0.015933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>3235</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.075816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>3236</td>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.954596</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>3237</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.958334</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>3238</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>0.016629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>3239</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.975919</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        z0        z1        z2  predicted_class\n",
       "0     2200  0.061739  0.929657  0.008604                1\n",
       "1     2201  0.000362  0.946300  0.053339                1\n",
       "2     2202  0.000468  0.978741  0.020791                1\n",
       "3     2203  0.889322  0.110299  0.000379                0\n",
       "4     2204  0.448965  0.535102  0.015933                1\n",
       "...    ...       ...       ...       ...              ...\n",
       "1035  3235  0.006570  0.917614  0.075816                1\n",
       "1036  3236  0.044705  0.954596  0.000698                1\n",
       "1037  3237  0.000007  0.958334  0.041658                1\n",
       "1038  3238  0.006783  0.976588  0.016629                1\n",
       "1039  3239  0.013774  0.975919  0.010307                1\n",
       "\n",
       "[1040 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_third = np.load(\"third_batch_multi.npz\")\n",
    "X_third = data_third[\"X\"]\n",
    "\n",
    "df_X_third = pd.DataFrame(X_third, columns=[\"user\", \"item\", \"rating\"])\n",
    "\n",
    "# Engineer features for the third dataset\n",
    "df_merged_third = engineer_features(df_X_third, top_features)\n",
    "\n",
    "# Scale the features\n",
    "X_third_scaled = scaler.transform(df_merged_third.drop(columns=[\"user\"]))\n",
    "\n",
    "# Predict probabilities for the third dataset\n",
    "y_pred_proba_third = model.predict_proba(X_third_scaled)\n",
    "\n",
    "# Create a DataFrame to hold user IDs and their corresponding class probabilities\n",
    "df_predictions_third = pd.DataFrame(\n",
    "    {\n",
    "        \"user\": df_merged_third[\"user\"],\n",
    "        \"z0\": y_pred_proba_third[:, 0],\n",
    "        \"z1\": y_pred_proba_third[:, 1],\n",
    "        \"z2\": y_pred_proba_third[:, 2],\n",
    "        \"predicted_class\": np.argmax(y_pred_proba_third, axis=1),\n",
    "    }\n",
    ")\n",
    "\n",
    "df_predictions_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061739</td>\n",
       "      <td>0.929657</td>\n",
       "      <td>0.008604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.053339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.978741</td>\n",
       "      <td>0.020791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.889322</td>\n",
       "      <td>0.110299</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.448965</td>\n",
       "      <td>0.535102</td>\n",
       "      <td>0.015933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.075816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.954596</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.958334</td>\n",
       "      <td>0.041658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.975919</td>\n",
       "      <td>0.010307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            z0        z1        z2\n",
       "0     0.061739  0.929657  0.008604\n",
       "1     0.000362  0.946300  0.053339\n",
       "2     0.000468  0.978741  0.020791\n",
       "3     0.889322  0.110299  0.000379\n",
       "4     0.448965  0.535102  0.015933\n",
       "...        ...       ...       ...\n",
       "1035  0.006570  0.917614  0.075816\n",
       "1036  0.044705  0.954596  0.000698\n",
       "1037  0.000007  0.958334  0.041658\n",
       "1038  0.006783  0.976588  0.016629\n",
       "1039  0.013774  0.975919  0.010307\n",
       "\n",
       "[1040 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_predictions_third.drop([\"user\", \"predicted_class\"], axis=\"columns\")\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    f\"./cs421-g1-team3-week10.npz\",\n",
    "    scores=df_final.to_numpy(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
