{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import seaborn as sns\n",
    "import random\n",
    "import joblib\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is trained on the combination of first_batch and second_batch to predict the third_batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.01)\n",
    "        Q3 = df[col].quantile(0.99)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Define the outlier range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Remove rows with outliers\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def engineer_features(df_X, top_features=None, df_y=None):\n",
    "    # Basic user features\n",
    "    df_user_features = df_X.groupby('user').agg(\n",
    "        mean_rating=('rating', 'mean'),\n",
    "        median_rating=('rating', 'median'),\n",
    "        std_rating=('rating', 'std'),\n",
    "        count_dislike=('rating', lambda x: (x == -10).sum()),\n",
    "        count_neutral=('rating', lambda x: (x == 0).sum()),\n",
    "        count_like=('rating', lambda x: (x == 10).sum()),\n",
    "        count_watched=('rating', lambda x: (x == 1).sum()),\n",
    "        total_interactions=('rating', 'count')\n",
    "    )\n",
    "\n",
    "    # Ratio features\n",
    "    \n",
    "    df_user_features['like_ratio'] = df_user_features['count_like'] / df_user_features['total_interactions']\n",
    "    df_user_features['dislike_ratio'] = df_user_features['count_dislike'] / df_user_features['total_interactions']\n",
    "    df_user_features['neutral_ratio'] = df_user_features['count_neutral'] / df_user_features['total_interactions']\n",
    "    df_user_features['watched_ratio'] = df_user_features['count_watched'] / df_user_features['total_interactions']\n",
    "\n",
    "    # Weighted scores\n",
    "    df_user_features['weighted_score'] = df_user_features['count_like'] * 1.5 - df_user_features['count_dislike'] * 1.5\n",
    "\n",
    "    # Distribution features\n",
    "    df_user_features['rating_kurtosis'] = df_X.groupby('user')['rating'].apply(lambda x: kurtosis(x))\n",
    "    \n",
    "    # Item popularity metrics\n",
    "    item_popularity = df_X.groupby('item')['rating'].agg(['mean', 'count'])\n",
    "    item_popularity['popularity_score'] = item_popularity['mean'] * np.log1p(item_popularity['count'])\n",
    "    \n",
    "    # Merge item popularity with user interactions\n",
    "    df_X_with_popularity = pd.merge(df_X, item_popularity['popularity_score'], left_on='item', right_index=True)\n",
    "    \n",
    "    # New features\n",
    "    df_user_features['avg_deviation_from_popularity'] = df_X_with_popularity.groupby('user').apply(\n",
    "    lambda x: np.abs(x['rating'] - x['popularity_score']).mean())\n",
    "\n",
    "    # Drop columns with high correlation\n",
    "    # Count watch has high correlation with total interactions\n",
    "    df_user_features.drop(columns=['total_interactions'], inplace=True)\n",
    "    df_user_features.drop(columns=['median_rating'], inplace=True)\n",
    "\n",
    "    # Drop columns with low mutual information\n",
    "    # NIL (for now)\n",
    "\n",
    "    # If labels are provided, merge with df_y\n",
    "    if df_y is not None:\n",
    "        # Remove outliers\n",
    "        df_user_features = remove_outliers(df_user_features, df_user_features.columns)\n",
    "        df_merged = pd.merge(df_user_features.reset_index(), df_y, on='user')\n",
    "\n",
    "        top_features = df_user_features.columns.tolist()\n",
    "\n",
    "        # Return the merged dataframe with selected features, label, and top features\n",
    "        return df_merged[['user'] + top_features + ['label']], top_features\n",
    "\n",
    "    # If no labels (unseen data), just select the top features\n",
    "    else:\n",
    "        # Ensure top_features is provided\n",
    "        if top_features is None:\n",
    "            raise ValueError(\"top_features must be provided for unseen data\")\n",
    "        \n",
    "        # Return the dataframe with only the selected top features\n",
    "        df_merged = df_user_features.reset_index()\n",
    "        return df_merged[['user'] + top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teoju\\AppData\\Local\\Temp\\ipykernel_30876\\212894115.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_user_features['avg_deviation_from_popularity'] = df_X_with_popularity.groupby('user').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Logistic Regression): {'estimator__warm_start': False, 'estimator__tol': 0.0001, 'estimator__solver': 'newton-cg', 'estimator__penalty': 'l2', 'estimator__max_iter': 2000, 'estimator__C': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "30 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\multiclass.py\", line 370, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\multiclass.py\", line 93, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\teoju\\Code\\SMU_Code\\2024-2025-S1\\CS421\\cs421-milton-project\\cs421-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.97294489 0.9625673  0.97342359 0.96258317 0.97344708 0.96258317\n",
      " 0.97300156        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_first = np.load(\"first_second_batch_multi_labels.npz\")\n",
    "X_first = data_first[\"X\"]\n",
    "y_first = data_first[\"yy\"]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_X_first = pd.DataFrame(X_first, columns=[\"user\", \"item\", \"rating\"])\n",
    "df_y_first = pd.DataFrame(y_first, columns=[\"user\", \"label\"])\n",
    "\n",
    "# Engineer features for the first dataset\n",
    "df_merged_first, top_features = engineer_features(df_X_first, df_y=df_y_first)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Features and Labels\n",
    "X_features_first = df_merged_first.drop(columns=['user', 'label'])\n",
    "y_labels_first = df_merged_first['label']\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_features_first)\n",
    "\n",
    "# Define base logistic regression model\n",
    "base_logreg = LogisticRegression(random_state=RANDOM_SEED)\n",
    "\n",
    "# Wrap it with OneVsRestClassifier\n",
    "ovr_logreg = OneVsRestClassifier(base_logreg)\n",
    "\n",
    "# Define parameter grid for logistic regression\n",
    "param_grid_logreg = {\n",
    "    'estimator__C': [0.1, 1, 10, 35, 100],  # Wider range of C values\n",
    "    'estimator__penalty': ['l2', 'l1'],  # Include L1 penalty\n",
    "    'estimator__solver': ['newton-cg', 'lbfgs', 'saga'],  # Include saga solver\n",
    "    'estimator__max_iter': [1000, 2000, 3000],  # Increased max_iter\n",
    "    'estimator__tol': [1e-4, 1e-5, 1e-6],  # Adjusted tolerance levels\n",
    "    'estimator__warm_start': [True, False],\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV for logistic regression\n",
    "random_search_logreg = RandomizedSearchCV(\n",
    "    estimator=ovr_logreg, \n",
    "    param_distributions=param_grid_logreg, \n",
    "    # Increase to 100 will marginally improve the results\n",
    "    n_iter=10,\n",
    "    scoring='roc_auc_ovr',\n",
    "    cv=10,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data (first dataset)\n",
    "random_search_logreg.fit(X_train_scaled, y_labels_first)\n",
    "\n",
    "# Print the best parameters found by RandomizedSearchCV\n",
    "print(f\"Best Parameters (Logistic Regression): {random_search_logreg.best_params_}\")\n",
    "\n",
    "# Use the best logistic regression model from RandomizedSearchCV\n",
    "best_logreg_model = random_search_logreg.best_estimator_\n",
    "model = best_logreg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'third_batch_multi.npz' with keys: X"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teoju\\AppData\\Local\\Temp\\ipykernel_30876\\212894115.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_user_features['avg_deviation_from_popularity'] = df_X_with_popularity.groupby('user').apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.061740</td>\n",
       "      <td>0.929656</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.053339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2202</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.978741</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2203</td>\n",
       "      <td>0.889322</td>\n",
       "      <td>0.110298</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2204</td>\n",
       "      <td>0.448969</td>\n",
       "      <td>0.535098</td>\n",
       "      <td>0.015933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>3235</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.075816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>3236</td>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.954596</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>3237</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.958334</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>3238</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>0.016629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>3239</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.975919</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        z0        z1        z2  predicted_class\n",
       "0     2200  0.061740  0.929656  0.008604                1\n",
       "1     2201  0.000362  0.946300  0.053339                1\n",
       "2     2202  0.000468  0.978741  0.020791                1\n",
       "3     2203  0.889322  0.110298  0.000379                0\n",
       "4     2204  0.448969  0.535098  0.015933                1\n",
       "...    ...       ...       ...       ...              ...\n",
       "1035  3235  0.006570  0.917614  0.075816                1\n",
       "1036  3236  0.044705  0.954596  0.000698                1\n",
       "1037  3237  0.000007  0.958334  0.041658                1\n",
       "1038  3238  0.006783  0.976588  0.016629                1\n",
       "1039  3239  0.013774  0.975919  0.010307                1\n",
       "\n",
       "[1040 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_third = np.load(\"third_batch_multi.npz\")\n",
    "X_third = data_third[\"X\"]\n",
    "\n",
    "df_X_third = pd.DataFrame(X_third, columns=[\"user\", \"item\", \"rating\"])\n",
    "\n",
    "# Engineer features for the third dataset\n",
    "df_merged_third = engineer_features(df_X_third, top_features)\n",
    "\n",
    "# Scale the features\n",
    "X_third_scaled = scaler.transform(df_merged_third.drop(columns=['user']))\n",
    "\n",
    "# Predict probabilities for the third dataset\n",
    "y_pred_proba_third = model.predict_proba(X_third_scaled)\n",
    "\n",
    "# Create a DataFrame to hold user IDs and their corresponding class probabilities\n",
    "df_predictions_third = pd.DataFrame({\n",
    "    'user': df_merged_third['user'],\n",
    "    'z0': y_pred_proba_third[:, 0],\n",
    "    'z1': y_pred_proba_third[:, 1],\n",
    "    'z2': y_pred_proba_third[:, 2],\n",
    "    'predicted_class': np.argmax(y_pred_proba_third, axis=1)\n",
    "})\n",
    "\n",
    "df_predictions_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061740</td>\n",
       "      <td>0.929656</td>\n",
       "      <td>0.008604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.946300</td>\n",
       "      <td>0.053339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.978741</td>\n",
       "      <td>0.020791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.889322</td>\n",
       "      <td>0.110298</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.448969</td>\n",
       "      <td>0.535098</td>\n",
       "      <td>0.015933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.075816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.954596</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.958334</td>\n",
       "      <td>0.041658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.975919</td>\n",
       "      <td>0.010307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            z0        z1        z2\n",
       "0     0.061740  0.929656  0.008604\n",
       "1     0.000362  0.946300  0.053339\n",
       "2     0.000468  0.978741  0.020791\n",
       "3     0.889322  0.110298  0.000379\n",
       "4     0.448969  0.535098  0.015933\n",
       "...        ...       ...       ...\n",
       "1035  0.006570  0.917614  0.075816\n",
       "1036  0.044705  0.954596  0.000698\n",
       "1037  0.000007  0.958334  0.041658\n",
       "1038  0.006783  0.976588  0.016629\n",
       "1039  0.013774  0.975919  0.010307\n",
       "\n",
       "[1040 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = df_predictions_third.drop(['user', 'predicted_class'], axis = 'columns')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "np.savez(f\"./cs421-g1-team3-week10-{time.time_ns()//1_000_000}.npz\", scores=df_final.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('cs421-g1-team3-week10-1729649099012.npz')['scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of predicted classes\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='predicted_class', data=df_predictions_third, palette='viridis', hue='predicted_class')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Predicted Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>z0</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.067784</td>\n",
       "      <td>0.919886</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.935905</td>\n",
       "      <td>0.063554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2202</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.927505</td>\n",
       "      <td>0.070810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2203</td>\n",
       "      <td>0.867079</td>\n",
       "      <td>0.132476</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2204</td>\n",
       "      <td>0.459407</td>\n",
       "      <td>0.520856</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>3235</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.900217</td>\n",
       "      <td>0.093158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>3236</td>\n",
       "      <td>0.045461</td>\n",
       "      <td>0.952631</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>3237</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.924614</td>\n",
       "      <td>0.075373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>3238</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.963849</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>3239</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>0.968890</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        z0        z1        z2  predicted_class\n",
       "0     2200  0.067784  0.919886  0.012330                1\n",
       "1     2201  0.000541  0.935905  0.063554                1\n",
       "2     2202  0.001684  0.927505  0.070810                1\n",
       "3     2203  0.867079  0.132476  0.000446                0\n",
       "4     2204  0.459407  0.520856  0.019737                1\n",
       "...    ...       ...       ...       ...              ...\n",
       "1035  3235  0.006625  0.900217  0.093158                1\n",
       "1036  3236  0.045461  0.952631  0.001908                1\n",
       "1037  3237  0.000013  0.924614  0.075373                1\n",
       "1038  3238  0.007833  0.963849  0.028318                1\n",
       "1039  3239  0.016816  0.968890  0.014293                1\n",
       "\n",
       "[1040 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_third['z1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_first = np.load(\"first_second_batch_multi_labels.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teoju\\AppData\\Local\\Temp\\ipykernel_30876\\388179390.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_user_features['avg_deviation_from_popularity'] = df_X_with_popularity.groupby('user').apply(\n"
     ]
    }
   ],
   "source": [
    "X_first = data_first[\"X\"]\n",
    "y_first = data_first[\"yy\"]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_X_first = pd.DataFrame(X_first, columns=[\"user\", \"item\", \"rating\"])\n",
    "df_y_first = pd.DataFrame(y_first, columns=[\"user\", \"label\"])\n",
    "\n",
    "# Engineer features for the first dataset\n",
    "df_merged_first, top_features = engineer_features(df_X_first, df_y=df_y_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_third = np.load(\"third_batch_multi.npz\")\n",
    "X_third = data_third[\"X\"]\n",
    "\n",
    "df_X_third = pd.DataFrame(X_first, columns=[\"user\", \"item\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>std_rating</th>\n",
       "      <th>count_dislike</th>\n",
       "      <th>count_neutral</th>\n",
       "      <th>count_like</th>\n",
       "      <th>count_watched</th>\n",
       "      <th>like_ratio</th>\n",
       "      <th>dislike_ratio</th>\n",
       "      <th>neutral_ratio</th>\n",
       "      <th>watched_ratio</th>\n",
       "      <th>weighted_score</th>\n",
       "      <th>rating_kurtosis</th>\n",
       "      <th>avg_deviation_from_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2200</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>4.328935</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>57</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.599777</td>\n",
       "      <td>10.777325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2201</td>\n",
       "      <td>2.773723</td>\n",
       "      <td>4.144438</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>90</td>\n",
       "      <td>0.252033</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.502281</td>\n",
       "      <td>11.626054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2202</td>\n",
       "      <td>-1.326679</td>\n",
       "      <td>4.812710</td>\n",
       "      <td>119</td>\n",
       "      <td>108</td>\n",
       "      <td>15</td>\n",
       "      <td>309</td>\n",
       "      <td>0.033860</td>\n",
       "      <td>0.268623</td>\n",
       "      <td>0.243792</td>\n",
       "      <td>0.697517</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>0.156543</td>\n",
       "      <td>11.994262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2203</td>\n",
       "      <td>4.432203</td>\n",
       "      <td>4.663880</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>63</td>\n",
       "      <td>0.423423</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-1.178190</td>\n",
       "      <td>9.846201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2204</td>\n",
       "      <td>1.804196</td>\n",
       "      <td>5.315747</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>78</td>\n",
       "      <td>0.254098</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.172131</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.486347</td>\n",
       "      <td>9.250028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>3235</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>4.600537</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>1.778435</td>\n",
       "      <td>10.651253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>3236</td>\n",
       "      <td>3.105839</td>\n",
       "      <td>4.572545</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>76</td>\n",
       "      <td>151</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.175966</td>\n",
       "      <td>0.648069</td>\n",
       "      <td>105.0</td>\n",
       "      <td>-0.010370</td>\n",
       "      <td>6.959701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>3237</td>\n",
       "      <td>1.542029</td>\n",
       "      <td>5.023677</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "      <td>202</td>\n",
       "      <td>0.213559</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.684746</td>\n",
       "      <td>49.5</td>\n",
       "      <td>0.914206</td>\n",
       "      <td>9.155213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>3238</td>\n",
       "      <td>2.617647</td>\n",
       "      <td>3.940257</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>67</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.683127</td>\n",
       "      <td>12.825187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>3239</td>\n",
       "      <td>2.529032</td>\n",
       "      <td>4.767735</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>92</td>\n",
       "      <td>0.272059</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.655946</td>\n",
       "      <td>8.571452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  mean_rating  std_rating  count_dislike  count_neutral  count_like  \\\n",
       "0     2200     2.714286    4.328935              2             11          21   \n",
       "1     2201     2.773723    4.144438              2             14          31   \n",
       "2     2202    -1.326679    4.812710            119            108          15   \n",
       "3     2203     4.432203    4.663880              1              7          47   \n",
       "4     2204     1.804196    5.315747             13             21          31   \n",
       "...    ...          ...         ...            ...            ...         ...   \n",
       "1035  3235     0.283784    4.600537              9              8           6   \n",
       "1036  3236     3.105839    4.572545              6             41          76   \n",
       "1037  3237     1.542029    5.023677             30             50          63   \n",
       "1038  3238     2.617647    3.940257              1             13          21   \n",
       "1039  3239     2.529032    4.767735              7             19          37   \n",
       "\n",
       "      count_watched  like_ratio  dislike_ratio  neutral_ratio  watched_ratio  \\\n",
       "0                57    0.262500       0.025000       0.137500       0.712500   \n",
       "1                90    0.252033       0.016260       0.113821       0.731707   \n",
       "2               309    0.033860       0.268623       0.243792       0.697517   \n",
       "3                63    0.423423       0.009009       0.063063       0.567568   \n",
       "4                78    0.254098       0.106557       0.172131       0.639344   \n",
       "...             ...         ...            ...            ...            ...   \n",
       "1035             51    0.090909       0.136364       0.121212       0.772727   \n",
       "1036            151    0.326180       0.025751       0.175966       0.648069   \n",
       "1037            202    0.213559       0.101695       0.169492       0.684746   \n",
       "1038             67    0.235955       0.011236       0.146067       0.752809   \n",
       "1039             92    0.272059       0.051471       0.139706       0.676471   \n",
       "\n",
       "      weighted_score  rating_kurtosis  avg_deviation_from_popularity  \n",
       "0               28.5         0.599777                      10.777325  \n",
       "1               43.5         0.502281                      11.626054  \n",
       "2             -156.0         0.156543                      11.994262  \n",
       "3               69.0        -1.178190                       9.846201  \n",
       "4               27.0         0.486347                       9.250028  \n",
       "...              ...              ...                            ...  \n",
       "1035            -4.5         1.778435                      10.651253  \n",
       "1036           105.0        -0.010370                       6.959701  \n",
       "1037            49.5         0.914206                       9.155213  \n",
       "1038            30.0         0.683127                      12.825187  \n",
       "1039            45.0         0.655946                       8.571452  \n",
       "\n",
       "[1040 rows x 14 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
